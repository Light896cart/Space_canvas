"""
âš ï¸ ONE-OFF SCRIPT
Ğ¦ĞµĞ»ÑŒ: Ğ¾Ğ´Ğ½Ğ¾ĞºÑ€Ğ°Ñ‚Ğ½Ğ°Ñ Ğ¾Ñ‡Ğ¸ÑÑ‚ĞºĞ° ĞºĞ¾Ğ»Ğ¾Ğ½ĞºĞ¸ 'subclass' Ğ² CSV-Ğ´Ğ°Ñ‚Ğ°ÑĞµÑ‚Ğµ.
ĞĞµ Ğ¿Ñ€ĞµĞ´Ğ½Ğ°Ğ·Ğ½Ğ°Ñ‡ĞµĞ½ Ğ´Ğ»Ñ Ğ¿ĞµÑ€ĞµĞ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ğ½Ğ¸Ñ.
Ğ—Ğ°Ğ¿ÑƒÑ‰ĞµĞ½: 2025-04-05, Ğ´Ğ°Ğ½Ğ½Ñ‹Ğµ Ğ¾Ğ±Ñ€Ğ°Ğ±Ğ¾Ñ‚Ğ°Ğ½Ñ‹.
"""
import os
import re

import pandas as pd
from sklearn.preprocessing import LabelEncoder
from joblib import Parallel, delayed
import pickle

def clean_subclass(sub):
    if pd.isna(sub) or sub == "unknown":
        return "unknown"
    # Ğ”ĞµĞ»Ğ¸Ğ¼ Ğ¿Ğ¾ ' (' Ğ¸ Ğ±ĞµÑ€Ñ‘Ğ¼ Ğ¿ĞµÑ€Ğ²ÑƒÑ Ñ‡Ğ°ÑÑ‚ÑŒ
    cleaned = str(sub).split(' (')[0]
    return cleaned.strip()

def coding_label_create(path_csv, path_output, n_jobs=-1, verbose=1):
    """
    ĞĞ±Ñ€Ğ°Ğ±Ğ°Ñ‚Ñ‹Ğ²Ğ°ĞµÑ‚ Ğ²ÑĞµ CSV-Ñ„Ğ°Ğ¹Ğ»Ñ‹ Ğ² Ğ¿Ğ°Ğ¿ĞºĞµ: ĞºĞ¾Ğ´Ğ¸Ñ€ÑƒĞµÑ‚ class Ğ¸ subclass, ÑĞ¾Ñ…Ñ€Ğ°Ğ½ÑĞµÑ‚ Ñ Ğ½Ğ¾Ğ²Ñ‹Ğ¼Ğ¸ ĞºĞ¾Ğ»Ğ¾Ğ½ĞºĞ°Ğ¼Ğ¸.

    Args:
        path_csv (str): ĞŸÑƒÑ‚ÑŒ Ğº Ğ¿Ğ°Ğ¿ĞºĞµ Ñ CSV-Ñ„Ğ°Ğ¹Ğ»Ğ°Ğ¼Ğ¸.
        path_output (str): ĞŸÑƒÑ‚ÑŒ Ğº Ğ¿Ğ°Ğ¿ĞºĞµ Ğ´Ğ»Ñ ÑĞ¾Ñ…Ñ€Ğ°Ğ½ĞµĞ½Ğ¸Ñ Ğ·Ğ°ĞºĞ¾Ğ´Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ½Ñ‹Ñ… Ñ„Ğ°Ğ¹Ğ»Ğ¾Ğ².
        n_jobs (int): ĞšĞ¾Ğ»Ğ¸Ñ‡ĞµÑÑ‚Ğ²Ğ¾ Ğ¿Ğ°Ñ€Ğ°Ğ»Ğ»ĞµĞ»ÑŒĞ½Ñ‹Ñ… Ğ¿Ñ€Ğ¾Ñ†ĞµÑÑĞ¾Ğ² (-1 = Ğ²ÑĞµ ÑĞ´Ñ€Ğ°).
        verbose (int): Ğ£Ñ€Ğ¾Ğ²ĞµĞ½ÑŒ Ğ»Ğ¾Ğ³Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ñ.
    """

    # Ğ¡Ğ¾Ğ·Ğ´Ğ°Ñ‘Ğ¼ Ğ²Ñ‹Ñ…Ğ¾Ğ´Ğ½ÑƒÑ Ğ¿Ğ°Ğ¿ĞºÑƒ
    os.makedirs(path_output, exist_ok=True)

    # Ğ¡Ğ¾Ğ±Ğ¸Ñ€Ğ°ĞµĞ¼ Ğ²ÑĞµ CSV-Ñ„Ğ°Ğ¹Ğ»Ñ‹
    csv_files = [f for f in os.listdir(path_csv) if f.lower().endswith('.csv')]
    if not csv_files:
        print("âŒ ĞĞµÑ‚ CSV-Ñ„Ğ°Ğ¹Ğ»Ğ¾Ğ² Ğ´Ğ»Ñ Ğ¾Ğ±Ñ€Ğ°Ğ±Ğ¾Ñ‚ĞºĞ¸.")
        return

    print(f"ğŸ” ĞĞ°Ğ¹Ğ´ĞµĞ½Ğ¾ {len(csv_files)} CSV-Ñ„Ğ°Ğ¹Ğ»Ğ¾Ğ².")

    # Ğ§Ğ¸Ñ‚Ğ°ĞµĞ¼ Ğ²ÑĞµ Ñ„Ğ°Ğ¹Ğ»Ñ‹ (Ğ»ĞµĞ½Ğ¸Ğ²Ğ¾ â€” Ñ‚Ğ¾Ğ»ÑŒĞºĞ¾ Ğ¸Ğ¼ĞµĞ½Ğ° Ğ¸ Ğ¿ĞµÑ€Ğ²Ñ‹Ğµ Ñ‡Ğ°ÑÑ‚Ğ¸, Ñ‡Ñ‚Ğ¾Ğ±Ñ‹ ÑĞ¾Ğ±Ñ€Ğ°Ñ‚ÑŒ ÑƒĞ½Ğ¸ĞºĞ°Ğ»ÑŒĞ½Ñ‹Ğµ Ğ¼ĞµÑ‚ĞºĞ¸)
    print("ğŸ”„ Ğ¡Ğ¾Ğ±Ğ¸Ñ€Ğ°ĞµĞ¼ ÑƒĞ½Ğ¸ĞºĞ°Ğ»ÑŒĞ½Ñ‹Ğµ Ğ·Ğ½Ğ°Ñ‡ĞµĞ½Ğ¸Ñ class Ğ¸ subclass Ğ´Ğ»Ñ ÑĞ¾Ğ³Ğ»Ğ°ÑĞ¾Ğ²Ğ°Ğ½Ğ½Ğ¾Ğ³Ğ¾ ĞºĞ¾Ğ´Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ñ...")

    all_classes = []
    all_subclasses = []

    for file in csv_files:
        df_chunk = pd.read_csv(os.path.join(path_csv, file), usecols=['class', 'subclass'],
                               nrows=100000)  # Ğ¾Ğ³Ñ€Ğ°Ğ½Ğ¸Ñ‡Ğ¸Ğ¼ Ğ´Ğ»Ñ ÑĞºĞ¾Ñ€Ğ¾ÑÑ‚Ğ¸
        all_classes.extend(df_chunk['class'].dropna().unique())
        all_subclasses.extend(df_chunk['subclass'].dropna().unique())

    # Ğ£Ğ½Ğ¸ĞºĞ°Ğ»Ğ¸Ğ·Ğ¸Ñ€ÑƒĞµĞ¼
    all_classes = list(set(all_classes))
    all_subclasses = list(set(all_subclasses))
    if "unknown" not in all_classes:
        all_classes.append("unknown")
    if "unknown" not in all_subclasses:
        all_subclasses.append("unknown")
    # Ğ¡Ğ¾Ğ·Ğ´Ğ°Ñ‘Ğ¼ LabelEncoder'Ñ‹
    le_class = LabelEncoder()
    le_subclass = LabelEncoder()

    le_class.fit(all_classes)
    le_subclass.fit(all_subclasses)
    print('all_classes', le_class)
    print('all_subclasses', le_subclass)
    # Ğ¡Ğ¾Ñ…Ñ€Ğ°Ğ½ÑĞµĞ¼ ÑĞ½ĞºĞ¾Ğ´ĞµÑ€Ñ‹ (Ğ½Ğ° Ğ±ÑƒĞ´ÑƒÑ‰ĞµĞµ, ĞµÑĞ»Ğ¸ Ğ¿Ğ¾Ğ½Ğ°Ğ´Ğ¾Ğ±Ğ¸Ñ‚ÑÑ Ğ´ĞµĞºĞ¾Ğ´Ğ¸Ñ€Ğ¾Ğ²Ğ°Ñ‚ÑŒ Ğ¸Ğ»Ğ¸ Ğ¾Ğ±Ñ€Ğ°Ğ±Ğ°Ñ‚Ñ‹Ğ²Ğ°Ñ‚ÑŒ Ğ½Ğ¾Ğ²Ñ‹Ğµ Ğ´Ğ°Ğ½Ğ½Ñ‹Ğµ)
    with open(os.path.join(path_output, 'label_encoder_class.pkl'), 'wb') as f:
        pickle.dump(le_class, f)
    with open(os.path.join(path_output, 'label_encoder_subclass.pkl'), 'wb') as f:
        pickle.dump(le_subclass, f)

    print(f"âœ… Ğ­Ğ½ĞºĞ¾Ğ´ĞµÑ€Ñ‹ Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ñ‹: {len(all_classes)} ÑƒĞ½Ğ¸ĞºĞ°Ğ»ÑŒĞ½Ñ‹Ñ… class, {len(all_subclasses)} subclass.")

    # Ğ¤ÑƒĞ½ĞºÑ†Ğ¸Ñ Ğ¾Ğ±Ñ€Ğ°Ğ±Ğ¾Ñ‚ĞºĞ¸ Ğ¾Ğ´Ğ½Ğ¾Ğ³Ğ¾ Ñ„Ğ°Ğ¹Ğ»Ğ°
    def process_file(filename):
        try:
            filepath = os.path.join(path_csv, filename)
            df = pd.read_csv(filepath)

            # ĞŸÑ€Ğ¾Ğ²ĞµÑ€ÑĞµĞ¼ Ğ½ÑƒĞ¶Ğ½Ñ‹Ğµ ĞºĞ¾Ğ»Ğ¾Ğ½ĞºĞ¸
            if 'class' not in df.columns or 'subclass' not in df.columns:
                print(f"âš ï¸ ĞŸÑ€Ğ¾Ğ¿ÑƒÑ‰ĞµĞ½ Ñ„Ğ°Ğ¹Ğ» {filename}: Ğ½ĞµÑ‚ ĞºĞ¾Ğ»Ğ¾Ğ½Ğ¾Ğº class/subclass")
                return

            # ĞšĞ¾Ğ´Ğ¸Ñ€ÑƒĞµĞ¼ (Ñ Ğ¾Ğ±Ñ€Ğ°Ğ±Ğ¾Ñ‚ĞºĞ¾Ğ¹ NaN)
            df['cod_class'] = le_class.transform(df['class'].fillna("unknown"))
            df['cod_subclass'] = le_subclass.transform(df['subclass'].fillna("unknown"))

            # Ğ¡Ğ¾Ñ…Ñ€Ğ°Ğ½ÑĞµĞ¼
            output_path = os.path.join(path_output, filename)
            df.to_csv(output_path, index=False)

            if verbose >= 2:
                print(f"âœ… ĞĞ±Ñ€Ğ°Ğ±Ğ¾Ñ‚Ğ°Ğ½: {filename}")

        except Exception as e:
            print(f"âŒ ĞÑˆĞ¸Ğ±ĞºĞ° Ğ¿Ñ€Ğ¸ Ğ¾Ğ±Ñ€Ğ°Ğ±Ğ¾Ñ‚ĞºĞµ {filename}: {e}")

    # ĞŸĞ°Ñ€Ğ°Ğ»Ğ»ĞµĞ»ÑŒĞ½Ğ°Ñ Ğ¾Ğ±Ñ€Ğ°Ğ±Ğ¾Ñ‚ĞºĞ° Ğ²ÑĞµÑ… Ñ„Ğ°Ğ¹Ğ»Ğ¾Ğ²
    print(f"ğŸš€ Ğ—Ğ°Ğ¿ÑƒÑĞºĞ°ĞµĞ¼ Ğ¾Ğ±Ñ€Ğ°Ğ±Ğ¾Ñ‚ĞºÑƒ {len(csv_files)} Ñ„Ğ°Ğ¹Ğ»Ğ¾Ğ²...")
    Parallel(n_jobs=n_jobs, verbose=verbose)(delayed(process_file)(f) for f in csv_files)

    print(f"âœ… Ğ“Ğ¾Ñ‚Ğ¾Ğ²Ğ¾! Ğ—Ğ°ĞºĞ¾Ğ´Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ½Ñ‹Ğµ Ñ„Ğ°Ğ¹Ğ»Ñ‹ ÑĞ¾Ñ…Ñ€Ğ°Ğ½ĞµĞ½Ñ‹ Ğ²: {path_output}")


# â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”
# ğŸš€ Ğ’Ñ‹Ğ·Ğ¾Ğ² Ñ„ÑƒĞ½ĞºÑ†Ğ¸Ğ¸
# â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”

path_csv = r"D:\Code\Space_canvas\data\raw_csv"
path_output = r"D:\Code\Space_canvas\data\encoded_csv"
n_jobs = -1
verbose = 1

coding_label_create(path_csv, path_output, n_jobs=-1, verbose=1)