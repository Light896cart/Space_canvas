from typing import List

import numpy as np
import wandb
from matplotlib import pyplot as plt
from torchvision import transforms
import torch.optim as optim
import torch
import torch.nn as nn
from tqdm import tqdm
from torch.utils.data import DataLoader
from pathlib import Path
from src.data.dataloader import create_train_val_dataloader
from src.metrics.classification import compute_batch_metrics
from src.model.model_architecture import BaseModel


def eval_model(
        model,
        val_dataset,
):
    # --- üü¢ –í–∞–ª–∏–¥–∞—Ü–∏—è ---
    model.eval()
    correct = 0
    total = 0
    with torch.no_grad():
        for batch in val_dataset:
            images, labels = batch
            images = images[:, :3, :, :]
            labels = labels[:, 0]
            outputs = model(images)
            _, predicted = torch.max(outputs, 1)
            total += labels.size(0)
            correct += (predicted == labels).sum().item()
            val_acc = correct / total
            print('–≠–¢–û –í–ê–õ –ê–°–°–ï–°', val_acc)


def train_model(
        folder: str,
        list_label: list[str],
        path_img: str,
        train_ratio: int | None = 0.9,
        list_extra: list[str] | None = None,
        transform: transforms.Compose | None = None,
        path_val_dataset: str | None = None
):
    """
    –û–±—É—á–µ–Ω–∏–µ –Ω–µ–π—Ä–æ–Ω–Ω–æ–π —Å–µ—Ç–∏

    Args:
        folder: –ü—É—Ç—å –¥–æ –ø–∞–ø–∫–∏ —Å csv —Ñ–∞–π–ª–∞–º–∏ (–¥–æ –¥–∞—Ç–∞—Å–µ—Ç–∞)
        list_label: –°–ø–∏—Å–æ–∫ —Å—Ç–æ–ª–±—Ü–æ–≤ –¥–ª—è –º–µ—Ç–æ–∫
        path_img: –ü—É—Ç—å –¥–æ –ø–∞–ø–∫–∏ —Å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è–º–∏
        train_ratio: –°–∫–æ–ª—å–∫–æ –¥–æ–ª–∂–Ω–æ –±—ã—Ç—å —Ç—Ä–µ–Ω–∏—Ä–æ–≤–æ—á–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö –≤ –ø—Ä–æ—Ü–µ–Ω—Ç–∞—Ö
        list_extra: –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ —ç–∫—Å—Ç—Ä–∞ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –∫–æ—Ç–æ—Ä—ã–µ –±—É–¥—É—Ç –≤–Ω–µ–¥—Ä—è—Ç—å –≤ –º–æ–¥–µ–ª—å –≤–º–µ—Å—Ç–µ —Å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ–º
        transform: –¢—Ä–∞–Ω—Å—Ñ–æ—Ä–º–∞—Ü–∏—è –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è (–∏–∑–º–µ–Ω–µ–Ω–∏–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è)
        path_val_dataset: –ï—Å–ª–∏ –µ—Å—Ç—å –ø—É—Ç—å –¥–æ csv —Ñ–∞–π–ª–∞ c –≤–∞–ª–∏–¥–∞—Ü–∏–æ–Ω–Ω—ã–º–∏ –¥–∞–Ω–Ω—ã–º–∏ –º–æ–∂–Ω–æ —É–∫–∞–∑–∞—Ç—å

    Return:
        None
    """
    model = BaseModel()
    folder = Path(folder)
    class_names = ['GALAXY','QSO','STAR']
    pattern = "chunk_*.csv"
    # –ü–æ–ª—É—á–∞–µ–º —Ñ–∞–π–ª—ã
    files = sorted(folder.glob(pattern))
    train_losses = []
    val_accuracies = []
    best_val_acc = 0.0
    best_model_wts = None
    weight_model_new = None
    bias_model_new = None
    # --- ‚öôÔ∏è –û–ø—Ç–∏–º–∏–∑–∞—Ç–æ—Ä –∏ –ª–æ—Å—Å ---
    optimizer = optim.AdamW(model.parameters(), lr=1e-4)
    criterion = nn.CrossEntropyLoss()
    val_dataset = None
    try:
        # --- üîÅ –¶–∏–∫–ª –æ–±—É—á–µ–Ω–∏—è ---
        model.train()
        for epoch in range(1):
            for path_csv in files:
                train_dataset, val_dataset = create_train_val_dataloader(
                    path_csv=path_csv,
                    path_img=path_img,
                    list_extra=list_extra,
                    list_label=list_label,
                    train_ratio=train_ratio,
                    transform=transform,
                    path_val_dataset=path_val_dataset
                )
                running_loss = 0.0
                progress_bar = tqdm(
                    train_dataset,
                    desc=f"Epoch {epoch + 1}/{epoch}",
                    unit="batch",
                    disable=not True,
                    leave=False
                )
                for step, batch in enumerate(progress_bar):
                    images, labels,coor = batch
                    images = images[:, :3, :, :]
                    labels = labels[:, 0]  # ‚Üê –í–ê–ñ–ù–û: (N, 1) ‚Üí (N,)


                    optimizer.zero_grad()
                    outputs = model(images)  # ‚Üê –î–û–õ–ñ–ù–û –ë–´–¢–¨: (N, 3)
                    loss = criterion(outputs, labels)
                    loss.backward()
                    optimizer.step()

                    # –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è –∏ –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–∏
                    preds = outputs.argmax(dim=1)

                    # üî• –í–ò–ó–£–ê–õ–ò–ó–ê–¶–ò–Ø –í–°–ï–• 32 –ò–ó–û–ë–†–ê–ñ–ï–ù–ò–ô
                    img_np = images.cpu().numpy()
                    true_labels = labels.cpu().numpy()
                    pred_labels = preds.cpu().numpy()

                    # –°–µ—Ç–∫–∞ 4x8
                    fig, axes = plt.subplots(4, 8, figsize=(16, 8))
                    axes = axes.ravel()

                    for i in range(32):
                        img = np.transpose(img_np[i], (1, 2, 0))  # (C,H,W) -> (H,W,C)
                        img = np.clip(img, 0, 1)
                        t = class_names[true_labels[i]]
                        p = class_names[pred_labels[i]]
                        print(f'–≠—Ç–æ {i} —Ñ–æ—Ç–æ–≥—Ä–∞—Ñ–∏—è')
                        print(coor[i])
                        print('-'*50)
                        axes[i].imshow(img)
                        axes[i].set_title(f"T: {t}\nP: {p} id {i}", color='green' if t == p else 'red', fontsize=8)
                        axes[i].axis('off')

                    plt.tight_layout()
                    plt.show()

                    probs = torch.softmax(outputs, dim=1)

                    # –í—ã—á–∏—Å–ª—è–µ–º –º–µ—Ç—Ä–∏–∫–∏ –ø–æ –±–∞—Ç—á—É
                    batch_metrics = compute_batch_metrics(labels, preds, probs, prefix="train")

                    # –î–æ–±–∞–≤–ª—è–µ–º loss
                    batch_metrics["train_loss"] = loss.item()

                    # –î–æ–±–∞–≤–ª—è–µ–º –Ω–æ–º–µ—Ä —à–∞–≥–∞ (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)
                    batch_metrics["step"] = epoch * len(train_dataset) + step

                    # üöÄ –û—Ç–ø—Ä–∞–≤–ª—è–µ–º –í–°–Å –≤ W&B
                    wandb.log(batch_metrics, commit=True)

                    # üñ® –û–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ: –≤—ã–≤–æ–¥ –≤ –∫–æ–Ω—Å–æ–ª—å
                    progress_bar.set_postfix({
                        "loss": f"{loss.item():.4f}",
                        "acc": f"{batch_metrics['train_acc']:.3f}",
                        "f1": f"{batch_metrics['train_f1']:.3f}"
                    })

    except KeyboardInterrupt:
        wandb.finish()
        eval_model(model,val_dataset)
